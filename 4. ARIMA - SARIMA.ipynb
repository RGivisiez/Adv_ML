{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA - SARIMA\n",
    "\n",
    "Não vou utilizar ARIMA ou SARIMA para fazer previsões sérias, é mais para aprender algumas técnicas e como separar os dataset de teste e treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ìndice\n",
    "\n",
    "1. [Resumo e objetivos](#Resumo-e-objetivos)\n",
    "- [Série temporal básica](#Série-temporal-básica)\n",
    "    - [O que é estacionaridade?](#O-que-é-estacionaridade?)\n",
    "    - [Checando estacionaridade](#Checando-estacionaridade)\n",
    "    - [Transformando em uma série estacionária](#Transformando-em-uma-série-estacionária)\n",
    "    - [Separando o dataset](#Separando-o-dataset)\n",
    "- [Série temporal](#Série-temporal)\n",
    "    - [ARIMA](#ARIMA)\n",
    "    - [SARIMA](#SARIMA)\n",
    "- [Apéndice](#Apéndice) \n",
    "    - [O que é a hipótese nula e como é utilizado no ADF teste](#null)\n",
    "    - [O andar do bêbado](#O-andar-do-bêbado)\n",
    "- [Referências](#Referências)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar:\n",
    "- [ ] Escolher uma loja para ser estudada. (Olhar na EDA)\n",
    "- [ ] O que é estacionaridade de um série temporal.\n",
    "- [ ] Tipos de estacionaridade. (Strict Stationary, Trend Stationary, Difference Stationary)\n",
    "- [ ] Como checar a estacionaridade.\n",
    "- [ ] Como fazer a série estacionária.\n",
    "\n",
    "- [A Gentle Introduction to Handling a Non-Stationary Time Series in Python](https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo e objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começar com:\n",
    "- https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
    "- https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/\n",
    "- https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "- https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "path = 'data'\n",
    "\n",
    "train = pd.read_csv(path + '/sales_train.csv.gz')\n",
    "test = pd.read_csv(path + '/test.csv.gz').set_index('ID')\n",
    "items = pd.read_csv(path + '/items.csv')\n",
    "items_cat = pd.read_csv(path + '/item_categories.csv')\n",
    "shops = pd.read_csv(path + '/shops.csv')\n",
    "geo = pd.read_csv(path + '/geo_shop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Série temporal básica\n",
    "\n",
    "- [O que é estacionaridade?](#O-que-é-estacionaridade?)\n",
    "- [Checando estacionaridade](#Checando-estacionaridade)\n",
    "- [Transformando em uma série estacionária](#Transformando-em-uma-série-estacionária)\n",
    "- [Separando o dataset](#Separando-o-dataset)\n",
    "- [Considerações finais](#Considerações-finais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que é estacionaridade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Artigo básico][1] [Artigo complexo][2] [ML][3]\n",
    "\n",
    "[1]: https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
    "[2]: https://www.quantstart.com/articles/Serial-Correlation-in-Time-Series-Analysis\n",
    "[3]: https://machinelearningmastery.com/time-series-data-stationary-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma série é considerada estacionária quando sua média, variância e convariância não mudam com o tempo. As séries abaixo não são estacionárias,\n",
    "\n",
    "![non-stationary](non-stat.png)\n",
    "\n",
    "- A primeira exibe uma tendência de subida.\n",
    "- Na segunda sua variância muda com o tempo. De forma mais simples, seu valor máximo e minímo ficam variando muito com o tempo.\n",
    "- A terceira exibe uma covariância com o tempo. De forma simples, o espaçamento entre os picos e vales deveriam ser iguais.\n",
    "\n",
    "Então o que de fato queremos é uma série perfeitinha, tipo essa,\n",
    "\n",
    "![non-stationary](stat.png)\n",
    "\n",
    "O que nunca vai acontecer no mundo real. Existem técnicas que transformam séries não estacionárias em estacionárias, algumas delas serão vistas nesse notebook. Para enteder mais da parte técnica recomendo esse [site][2], mas é bom já ter uma base matemática boa antes de ler. Esse [site][1] é mais simples e também muito bom, inclusive tirei as figuras de lá.\n",
    "\n",
    "[1]: https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
    "[2]: https://www.quantstart.com/articles/Serial-Correlation-in-Time-Series-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checando estacionaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem sempre vai ser possível checar no olho se a série é estacionária ou não. Precisamos utilizar alguns testes matemáticos para isso, então vamos pegar uma loja do dataset e fazer algumas analizes. \n",
    "\n",
    "> Esse dataset não é muito bom para fazer esse tipo de coisa, ele é muito simples. Eu deixei nas referências dois kerneis com dataset melhores para isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vou unir o dataset todo, agrupar tudo por mês e escolher uma loja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unindo o dataset.\n",
    "train_full = pd.merge(train, items, on='item_id', how='left')\n",
    "train_full = pd.merge(train_full, items_cat, on='item_category_id', how='left')\n",
    "train_full = pd.merge(train_full, shops, on='shop_id', how='left')\n",
    "train_clean = train_full.drop(['date', 'item_name', 'shop_name', 'item_category_name'], axis=1)\n",
    "train_clean['revenue'] = train_full['item_cnt_day'] * train_full['item_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando por mês.\n",
    "df = train_clean.pivot_table(index=['shop_id'], \n",
    "                             columns=['date_block_num'],\n",
    "                             values=['item_cnt_day'],\n",
    "                             aggfunc='sum', fill_value=0)\n",
    "\n",
    "df.columns = df.columns.droplevel(0)\n",
    "\n",
    "# Array com o número de meses:\n",
    "months = train_clean['date_block_num'].nunique()\n",
    "\n",
    "# Datas para serem colocadas no eixo x:\n",
    "date_range = pd.date_range(start='1/2013', periods=months, freq='M')\n",
    "date_range = [ str(date_range.year[month]) + '/' + str(date_range.month_name()[month]) for month in range(months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loja 37 é uma boa escolha.\n",
    "shop = 37\n",
    "\n",
    "items_sold = df.loc[shop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "shop 37",
         "type": "scatter",
         "uid": "50c5e40a-33c8-4d9c-b4a5-fd5e2a35e514",
         "x": [
          "2013/January",
          "2013/February",
          "2013/March",
          "2013/April",
          "2013/May",
          "2013/June",
          "2013/July",
          "2013/August",
          "2013/September",
          "2013/October",
          "2013/November",
          "2013/December",
          "2014/January",
          "2014/February",
          "2014/March",
          "2014/April",
          "2014/May",
          "2014/June",
          "2014/July",
          "2014/August",
          "2014/September",
          "2014/October",
          "2014/November",
          "2014/December",
          "2015/January",
          "2015/February",
          "2015/March",
          "2015/April",
          "2015/May",
          "2015/June",
          "2015/July",
          "2015/August",
          "2015/September",
          "2015/October"
         ],
         "xaxis": "x",
         "y": [
          2399,
          2216,
          2629,
          1946,
          2019,
          1829,
          1293,
          1472,
          1666,
          1169,
          1308,
          1693,
          1125,
          1110,
          1246,
          944,
          1040,
          1065,
          997,
          1240,
          1213,
          1074,
          1496,
          1953,
          1144,
          988,
          990,
          1109,
          979,
          804,
          1041,
          1248,
          978,
          833
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 500,
        "title": {
         "text": "Nº de itens vendidos por mês"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\" style=\"height: 500px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\")) {\n",
       "    Plotly.newPlot(\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\", [{\"name\": \"shop 37\", \"x\": [\"2013/January\", \"2013/February\", \"2013/March\", \"2013/April\", \"2013/May\", \"2013/June\", \"2013/July\", \"2013/August\", \"2013/September\", \"2013/October\", \"2013/November\", \"2013/December\", \"2014/January\", \"2014/February\", \"2014/March\", \"2014/April\", \"2014/May\", \"2014/June\", \"2014/July\", \"2014/August\", \"2014/September\", \"2014/October\", \"2014/November\", \"2014/December\", \"2015/January\", \"2015/February\", \"2015/March\", \"2015/April\", \"2015/May\", \"2015/June\", \"2015/July\", \"2015/August\", \"2015/September\", \"2015/October\"], \"y\": [2399, 2216, 2629, 1946, 2019, 1829, 1293, 1472, 1666, 1169, 1308, 1693, 1125, 1110, 1246, 944, 1040, 1065, 997, 1240, 1213, 1074, 1496, 1953, 1144, 988, 990, 1109, 979, 804, 1041, 1248, 978, 833], \"type\": \"scatter\", \"uid\": \"50c5e40a-33c8-4d9c-b4a5-fd5e2a35e514\", \"xaxis\": \"x\", \"yaxis\": \"y\"}], {\"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 900, \"title\": {\"text\": \"N\\u00ba de itens vendidos por m\\u00eas\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\" style=\"height: 500px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\")) {\n",
       "    Plotly.newPlot(\"25934ef5-ebb3-46dd-843a-95ae13c39cd2\", [{\"name\": \"shop 37\", \"x\": [\"2013/January\", \"2013/February\", \"2013/March\", \"2013/April\", \"2013/May\", \"2013/June\", \"2013/July\", \"2013/August\", \"2013/September\", \"2013/October\", \"2013/November\", \"2013/December\", \"2014/January\", \"2014/February\", \"2014/March\", \"2014/April\", \"2014/May\", \"2014/June\", \"2014/July\", \"2014/August\", \"2014/September\", \"2014/October\", \"2014/November\", \"2014/December\", \"2015/January\", \"2015/February\", \"2015/March\", \"2015/April\", \"2015/May\", \"2015/June\", \"2015/July\", \"2015/August\", \"2015/September\", \"2015/October\"], \"y\": [2399, 2216, 2629, 1946, 2019, 1829, 1293, 1472, 1666, 1169, 1308, 1693, 1125, 1110, 1246, 944, 1040, 1065, 997, 1240, 1213, 1074, 1496, 1953, 1144, 988, 990, 1109, 979, 804, 1041, 1248, 978, 833], \"type\": \"scatter\", \"uid\": \"50c5e40a-33c8-4d9c-b4a5-fd5e2a35e514\", \"xaxis\": \"x\", \"yaxis\": \"y\"}], {\"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"height\": 500, \"width\": 900, \"title\": {\"text\": \"N\\u00ba de itens vendidos por m\\u00eas\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x=date_range,\n",
    "    y=items_sold,\n",
    "    name='shop ' + str(shop),\n",
    ")\n",
    "fig = tools.make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "\n",
    "fig['layout'].update(height=500, width=900, title='Nº de itens vendidos por mês',\n",
    "                     xaxis = dict())\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer o teste e mostrar os resultados.\n",
    "\n",
    "def adf_teste(time_series, regression, maxlag=0):\n",
    "    #Fazendo o teste.\n",
    "    adf_test = adfuller(items_sold, regression=regression, maxlag=maxlag, autolag=None)\n",
    "\n",
    "    # Arrumando as variáveis para o print.\n",
    "    adf_output = pd.Series(adf_test[0:4], index=['Test Statistic','p-value',\n",
    "                                                 '#Lags Used',\n",
    "                                                 'Number of Observations Used'])\n",
    "    for percent, value in dftest[4].items():\n",
    "        \n",
    "        adf_output['Critical Value (%s)' % percent] = value\n",
    "        \n",
    "    print('Resultados ADF: \\n')\n",
    "    print(adf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados ADF: \n",
      "\n",
      "Test Statistic                 -3.400633\n",
      "p-value                         0.051303\n",
      "#Lags Used                      0.000000\n",
      "Number of Observations Used    33.000000\n",
      "Critical Value (1%)            -3.752928\n",
      "Critical Value (5%)            -2.998500\n",
      "Critical Value (10%)           -2.638967\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adf_teste(osc_0, 'ct', maxlag=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for kpss test\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "#define KPSS\n",
    "def kpss_test(timeseries):\n",
    "    print ('Results of KPSS Test:')\n",
    "    kpsstest = kpss(timeseries, regression='c')\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
    "    for key,value in kpsstest[3].items():\n",
    "        kpss_output['Critical Value (%s)'%key] = value\n",
    "    print(kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of KPSS Test:\n",
      "Test Statistic            1.93871\n",
      "p-value                   0.01000\n",
      "Lags Used                17.00000\n",
      "Critical Value (10%)      0.34700\n",
      "Critical Value (5%)       0.46300\n",
      "Critical Value (2.5%)     0.57400\n",
      "Critical Value (1%)       0.73900\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronaldo/anaconda3/envs/Data_Science/lib/python3.6/site-packages/statsmodels/tsa/stattools.py:1276: InterpolationWarning:\n",
      "\n",
      "p-value is smaller than the indicated p-value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kpss_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADF (Augmented Dickey Fuller) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados ADF: \n",
      "\n",
      "Test Statistic                 -2.658821\n",
      "p-value                         0.081439\n",
      "#Lags Used                      0.000000\n",
      "Number of Observations Used    33.000000\n",
      "Critical Value (1%)            -3.752928\n",
      "Critical Value (5%)            -2.998500\n",
      "Critical Value (10%)           -2.638967\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o teste.\n",
    "adf_test = adfuller(items_sold, regression='c', maxlag=0, autolag='AIC')\n",
    "\n",
    "# Arrumando as variáveis para o print.\n",
    "adf_output = pd.Series(adf_test[0:4], index=['Test Statistic','p-value',\n",
    "                                             '#Lags Used',\n",
    "                                             'Number of Observations Used'])\n",
    "for percent, value in dftest[4].items():\n",
    "    \n",
    "    adf_output['Critical Value (%s)' % percent] = value\n",
    "        \n",
    "print('Resultados ADF: \\n')\n",
    "print(adf_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que essa série não é estacionária, é fácil de ver a tendência de queda nas vendas e a variância (minímo e máximo) assumindo valores diferentes no tempo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando em uma série estacionária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando o dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Série temporal\n",
    "\n",
    "   - [Random Walk](#Random-walk)\n",
    "   - [ARIMA](#ARIMA)\n",
    "   - [SARIMA](#SARIMA)\n",
    "   - [Considerações finais](#Considerações-finais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apéndice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que é a hipótese nula e como é utilizado no ADF teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show off:\n",
    "\n",
    "1. Explicar o teste ADF de verdade:\n",
    "    \n",
    "    - Explicar de forma geral o que é a hipótese nula e dar o exemplo dos dados.\n",
    "    - Explicitar como o p-value ajuda na inferência da hipótese.\n",
    "    - Começar assumindo o random walk, sem dar muito explicação.\n",
    "    - Falar da raíz unitária, sem dar muita explicação.\n",
    "    - Aplicar ao teste ADF a Null hypothesis e definir qual é a nossa hipótese.\n",
    "    - Explicar o p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null hypothesis ($H_0$): Existe uma raiz unitária, indicando que a série não é estacionária.\n",
    "- Alternate Hypothesis ($H_1$): Não existe uma raiz unitária, indicando que a série é estacionária.\n",
    "\n",
    ">Se minha hipótese $H_0$ é falsa então $H_1$ é obrigatoriamente verdadeira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**p-value** é a probabilidade do evento ocorrer.\n",
    "\n",
    "- Se p-value < 5% o evento é pouco provável, ou seja, podemos considerar que não ocorre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que queremos mostrar é que, olhando para os dados que temos, $H_0$ é pouco provável que aconteça, logo $H_1$ é acotence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "livro https://www.stata.com/manuals13/tsdfuller.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/P-value#cite_note-7\n",
    "The p-value is used in the context of null hypothesis testing in order to quantify the idea of statistical significance of evidence.[note 1] Null hypothesis testing is a reductio ad absurdum argument adapted to statistics. In essence, a claim is assumed valid if its counter-claim is improbable.\n",
    "\n",
    "As such, the only hypothesis that needs to be specified in this test and which embodies the counter-claim is referred to as the null hypothesis (that is, the hypothesis to be nullified). A result is said to be statistically significant if it allows us to reject the null hypothesis. That is, as per the reductio ad absurdum reasoning, the statistically significant result should be highly improbable if the null hypothesis is assumed to be true. The rejection of the null hypothesis implies that the correct hypothesis lies in the logical complement of the null hypothesis. However, unless there is a single alternative to the null hypothesis, the rejection of null hypothesis does not tell us which of the alternatives might be the correct one.\n",
    "\n",
    "\n",
    "The smaller the p-value, the higher the significance because it tells the investigator that the hypothesis under consideration may not adequately explain the observation. The null hypothesis {\\displaystyle H} H is rejected if any of these probabilities is less than or equal to a small, fixed but arbitrarily pre-defined threshold value {\\displaystyle \\alpha } \\alpha , which is referred to as the level of significance.\n",
    "\n",
    "**One roll of a pair of dice**\n",
    "Suppose a researcher rolls a pair of dice once and assumes a null hypothesis that the dice are fair, not loaded or weighted toward any specific number/roll/result; uniform. The test statistic is \"the sum of the rolled numbers\" and is one-tailed. The researcher rolls the dice and observes that both dice show 6, yielding a test statistic of 12. The p-value of this outcome is 1/36 (because under the assumption of the null hypothesis, the test statistic is uniformly distributed) or about 0.028 (the highest test statistic out of 6×6 = 36 possible outcomes). If the researcher assumed a significance level of 0.05, this result would be deemed significant and the hypothesis that the dice are fair would be rejected.\n",
    "\n",
    "In this case, a single roll provides a very weak basis (that is, insufficient data) to draw a meaningful conclusion about the dice. This illustrates the danger with blindly applying p-value without considering the experiment design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O andar do bêbado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar o random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.stata.com/manuals13/tsdfuller.pdf\n",
    "- Pure Random Walk (Yt = Yt-1 + εt ) Random walk predicts that the value at time \"t\" will be equal to the last period value plus a stochastic (non-systematic) component that is a white noise, which means εt is independent and identically distributed with mean \"0\" and variance \"σ².\" Random walk can also be named a process integrated of some order, a process with a unit root or a process with a stochastic trend. It is a non-mean-reverting process that can move away from the mean either in a positive or negative direction. Another characteristic of a random walk is that the variance evolves over time and goes to infinity as time goes to infinity; therefore, a random walk cannot be predicted.\n",
    "- Random Walk with Drift (Yt = α + Yt-1 + εt ) If the random walk model predicts that the value at time \"t\" will equal the last period's value plus a constant, or drift (α), and a white noise term (εt), then the process is random walk with a drift. It also does not revert to a long-run mean and has variance dependent on time.\n",
    "- Deterministic Trend (Yt = α + βt + εt ) Often a random walk with a drift is confused for a deterministic trend. Both include a drift and a white noise component, but the value at time \"t\" in the case of a random walk is regressed on the last period's value (Yt-1), while in the case of a deterministic trend it is regressed on a time trend (βt). A non-stationary process with a deterministic trend has a mean that grows around a fixed trend, which is constant and independent of time.\n",
    "- Random Walk with Drift and Deterministic Trend (Yt = α + Yt-1 + βt + εt ) Another example is a non-stationary process that combines a random walk with a drift component (α) and a deterministic trend (βt). It specifies the value at time \"t\" by the last period's value, a drift, a trend and a stochastic component. (To learn more about random walks and trends, see our Financial Concepts tutorial.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "- O material parece bem embasado e tem um carater mais técnico: [QuantStart](https://www.quantstart.com/articles#time-series-analysis)\n",
    "- Mais um material técnico: [Fuqua School of Business](http://people.duke.edu/~rnau/411home.htm)\n",
    "- Passo a passo para time series forecasting: [Comprehensive guide to creating time series forecast](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/) <- Esse site parece bom.\n",
    "- [Univariate versus Multivariate](https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/)\n",
    "- [Co2 Emission Forecast ARIMA](https://www.kaggle.com/berhag/co2-emission-forecast-with-python-seasonal-arima)\n",
    "- [Climate Change Forecast SARIMA](https://www.kaggle.com/leandrovrabelo/climate-change-forecast-sarima-model?utm_medium=email&utm_source=intercom&utm_campaign=datanotes-2019)\n",
    "- Outro site mais técnico: [Forecasting: Principles and Practice](https://otexts.com/fpp2/non-seasonal-arima.html)\n",
    "- 2[A Gentle Introduction to Handling a Non-Stationary Time Series in Python](https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/)\n",
    "- [1](https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/) <- Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
